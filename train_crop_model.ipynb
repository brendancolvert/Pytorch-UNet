{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "from unet.unet_model import UNet\n",
    "\n",
    "from utils.dataset import CrossValDataset\n",
    "from utils.model_eval import dice_coefficient\n",
    "from utils.data import RegressorDataset\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "## Device\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print('Using GPU')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Model\n",
    "modelpath = \"D:/autopos/train/unet-save2_13.pth\"\n",
    "pretrained_model = torch.load(modelpath, map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset\n",
    "groupPath  = \"D:/autopos/train\"\n",
    "originPath = \"D:/autopos/train/origin.csv\"\n",
    "batch_size = 8\n",
    "\n",
    "## Training\n",
    "n_channels = 1\n",
    "n_classes = 13\n",
    "\n",
    "learning_rate = 1e-3\n",
    "weight_decay  = 1e-8\n",
    "momentum      = 0.9\n",
    "\n",
    "num_epochs    = 11\n",
    "\n",
    "##Cropping\n",
    "D = 350\n",
    "N = 512\n",
    "xc=0\n",
    "yc=0\n",
    "centermode = 'rand'\n",
    "mu = np.array([0,0])\n",
    "sigma= 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model.\n",
      "Train: 9.246841430664062\n",
      "Train: 5.990595817565918\n",
      "Train: 6.013113498687744\n",
      "Train: 2.3448214530944824\n",
      "Train: 1.25921630859375\n",
      "Train: 1.145085334777832\n",
      "Train: 0.8413614630699158\n",
      "Train: 2.163578748703003\n",
      "Train: 0.7918638586997986\n",
      "Train: 0.8720099925994873\n",
      "Train: 0.8886170387268066\n",
      "Train: 1.193792462348938\n",
      "Test: 3564.714599609375\n",
      "Test: 3301.105712890625\n",
      "Test: 4175.58056640625\n",
      "Train: 0.6596277952194214\n",
      "Train: 0.8164217472076416\n",
      "Train: 0.6506467461585999\n",
      "Train: 0.6111125946044922\n",
      "Train: 0.5059539079666138\n",
      "Train: 0.47596341371536255\n",
      "Train: 0.43259239196777344\n",
      "Train: 0.3946937918663025\n",
      "Train: 0.3539423942565918\n",
      "Train: 0.3193109333515167\n",
      "Train: 0.3999567925930023\n",
      "Train: 0.7124047875404358\n",
      "Test: 119.63856506347656\n",
      "Test: 106.7889404296875\n",
      "Test: 114.81185150146484\n",
      "Train: 0.3193693161010742\n",
      "Train: 0.47957828640937805\n",
      "Train: 0.37186485528945923\n",
      "Train: 0.3694743514060974\n",
      "Train: 0.37247592210769653\n",
      "Train: 0.3057083189487457\n",
      "Train: 0.2823525667190552\n",
      "Train: 0.28372007608413696\n",
      "Train: 0.24310654401779175\n",
      "Train: 0.2773037254810333\n",
      "Train: 0.29393982887268066\n",
      "Train: 0.6252958178520203\n",
      "Test: 7.116055011749268\n",
      "Test: 5.06109619140625\n",
      "Test: 5.138186454772949\n",
      "Train: 0.23832270503044128\n",
      "Train: 0.39082345366477966\n",
      "Train: 0.32495346665382385\n",
      "Train: 0.3373081386089325\n",
      "Train: 0.29832005500793457\n",
      "Train: 0.35447177290916443\n",
      "Train: 0.2409714162349701\n",
      "Train: 0.23479250073432922\n",
      "Train: 0.23348018527030945\n",
      "Train: 0.2101755142211914\n",
      "Train: 0.28802067041397095\n",
      "Train: 0.4728943407535553\n",
      "Test: 1.1378452777862549\n",
      "Test: 1.1622165441513062\n",
      "Test: 1.0192416906356812\n",
      "Train: 0.21516834199428558\n",
      "Train: 0.38605549931526184\n",
      "Train: 0.24511688947677612\n",
      "Train: 0.25801557302474976\n",
      "Train: 0.2462666630744934\n",
      "Train: 0.2879820168018341\n",
      "Train: 0.21140339970588684\n",
      "Train: 0.21151483058929443\n",
      "Train: 0.16121573746204376\n",
      "Train: 0.19055142998695374\n",
      "Train: 0.23243407905101776\n",
      "Train: 0.5055428147315979\n",
      "Test: 0.7029355764389038\n",
      "Test: 0.6254547238349915\n",
      "Test: 0.5042253732681274\n",
      "Train: 0.18071883916854858\n",
      "Train: 0.4050203561782837\n",
      "Train: 0.3052038848400116\n",
      "Train: 0.275082528591156\n",
      "Train: 0.21718910336494446\n",
      "Train: 0.22221951186656952\n",
      "Train: 0.28836071491241455\n",
      "Train: 0.20842626690864563\n",
      "Train: 0.1706833839416504\n",
      "Train: 0.19832128286361694\n",
      "Train: 0.26634731888771057\n",
      "Train: 0.5732248425483704\n",
      "Test: 0.3037250339984894\n",
      "Test: 0.2254153937101364\n",
      "Test: 0.18845877051353455\n",
      "Train: 0.20126432180404663\n",
      "Train: 0.3666051924228668\n",
      "Train: 0.2334681898355484\n",
      "Train: 0.2617639899253845\n",
      "Train: 0.21476304531097412\n",
      "Train: 0.21874386072158813\n",
      "Train: 0.21610571444034576\n",
      "Train: 0.20415356755256653\n",
      "Train: 0.1556009203195572\n",
      "Train: 0.1531544327735901\n",
      "Train: 0.19679735600948334\n",
      "Train: 0.47653722763061523\n",
      "Test: 0.47520607709884644\n",
      "Test: 0.4974253177642822\n",
      "Test: 0.44529348611831665\n",
      "Train: 0.150623619556427\n",
      "Train: 0.3328402042388916\n",
      "Train: 0.16861234605312347\n",
      "Train: 0.23977817595005035\n",
      "Train: 0.1673542559146881\n",
      "Train: 0.1795147806406021\n",
      "Train: 0.15326239168643951\n",
      "Train: 0.14899227023124695\n",
      "Train: 0.11745353788137436\n",
      "Train: 0.14641547203063965\n",
      "Train: 0.18286998569965363\n",
      "Train: 0.37627339363098145\n",
      "Test: 0.34915900230407715\n",
      "Test: 0.29510557651519775\n",
      "Test: 0.32723623514175415\n",
      "Train: 0.13159434497356415\n",
      "Train: 0.287982702255249\n",
      "Train: 0.16817069053649902\n",
      "Train: 0.17771321535110474\n",
      "Train: 0.1518503725528717\n",
      "Train: 0.155714750289917\n",
      "Train: 0.15064571797847748\n",
      "Train: 0.1295192837715149\n",
      "Train: 0.11752720177173615\n",
      "Train: 0.1535012423992157\n",
      "Train: 0.17483846843242645\n",
      "Train: 0.4855712950229645\n",
      "Test: 0.2478850930929184\n",
      "Test: 0.14355598390102386\n",
      "Test: 0.14252109825611115\n",
      "Train: 0.11967402696609497\n",
      "Train: 0.30363720655441284\n",
      "Train: 0.16665898263454437\n",
      "Train: 0.19490885734558105\n",
      "Train: 0.1479312926530838\n",
      "Train: 0.18669477105140686\n",
      "Train: 0.13976609706878662\n",
      "Train: 0.13532118499279022\n",
      "Train: 0.11280082166194916\n",
      "Train: 0.12694735825061798\n",
      "Train: 0.16899263858795166\n",
      "Train: 0.43795502185821533\n",
      "Test: 0.22813688218593597\n",
      "Test: 0.14165987074375153\n",
      "Test: 0.13923119008541107\n",
      "Train: 0.11574172973632812\n",
      "Train: 0.28840523958206177\n",
      "Train: 0.15791738033294678\n",
      "Train: 0.12837167084217072\n",
      "Train: 0.1566232293844223\n",
      "Train: 0.15901686251163483\n",
      "Train: 0.12532711029052734\n",
      "Train: 0.13157369196414948\n",
      "Train: 0.10591548681259155\n",
      "Train: 0.12323110550642014\n",
      "Train: 0.15959209203720093\n",
      "Train: 0.4096086323261261\n",
      "Test: 0.20385698974132538\n",
      "Test: 0.13256771862506866\n",
      "Test: 0.1378912627696991\n",
      "Loaded pretrained model.\n",
      "Train: 9.18455982208252\n",
      "Train: 6.120625972747803\n",
      "Train: 6.774045944213867\n",
      "Train: 2.015519380569458\n",
      "Train: 1.8460443019866943\n",
      "Train: 1.5861892700195312\n",
      "Train: 1.1250756978988647\n",
      "Train: 0.9745702147483826\n",
      "Train: 0.8420445322990417\n",
      "Train: 0.828170895576477\n",
      "Train: 0.8412607908248901\n",
      "Train: 1.2465611696243286\n",
      "Test: 17284.216796875\n",
      "Test: 16425.291015625\n",
      "Test: 15961.3076171875\n",
      "Train: 0.7494525909423828\n",
      "Train: 0.9897260665893555\n",
      "Train: 0.7960917949676514\n",
      "Train: 0.6927865743637085\n",
      "Train: 0.6598972082138062\n",
      "Train: 0.6001049876213074\n",
      "Train: 0.5268914699554443\n",
      "Train: 0.45777183771133423\n",
      "Train: 0.35914549231529236\n",
      "Train: 0.39908337593078613\n",
      "Train: 0.4227578639984131\n",
      "Train: 0.642130434513092\n",
      "Test: 149.86904907226562\n",
      "Test: 125.17132568359375\n",
      "Test: 84.11503601074219\n",
      "Train: 0.38160979747772217\n",
      "Train: 0.4954199492931366\n",
      "Train: 0.4439823627471924\n",
      "Train: 0.3901312053203583\n",
      "Train: 0.32929790019989014\n",
      "Train: 0.44539570808410645\n",
      "Train: 0.27732759714126587\n",
      "Train: 0.2895098924636841\n",
      "Train: 0.3780381977558136\n",
      "Train: 0.29421815276145935\n",
      "Train: 0.35135167837142944\n",
      "Train: 0.6144514679908752\n",
      "Test: 0.7585095167160034\n",
      "Test: 0.8107461929321289\n",
      "Test: 0.823067843914032\n",
      "Train: 0.3055116534233093\n",
      "Train: 0.4977549612522125\n",
      "Train: 0.43264126777648926\n",
      "Train: 0.3766273856163025\n",
      "Train: 0.29653891921043396\n",
      "Train: 0.3613831400871277\n",
      "Train: 0.2873229384422302\n",
      "Train: 0.26174065470695496\n",
      "Train: 0.23955272138118744\n",
      "Train: 0.23279283940792084\n",
      "Train: 0.28424590826034546\n",
      "Train: 0.5082224011421204\n",
      "Test: 0.870162308216095\n",
      "Test: 0.902604877948761\n",
      "Test: 0.8012703061103821\n",
      "Train: 0.21914906799793243\n",
      "Train: 0.35075873136520386\n",
      "Train: 0.2544083595275879\n",
      "Train: 0.33617061376571655\n",
      "Train: 0.22740572690963745\n",
      "Train: 0.3027794659137726\n",
      "Train: 0.2011319249868393\n",
      "Train: 0.19032230973243713\n",
      "Train: 0.17642013728618622\n",
      "Train: 0.19770017266273499\n",
      "Train: 0.23855839669704437\n",
      "Train: 0.4515896141529083\n",
      "Test: 0.25911322236061096\n",
      "Test: 0.20895323157310486\n",
      "Test: 0.2337343692779541\n",
      "Train: 0.16613543033599854\n",
      "Train: 0.3716776967048645\n",
      "Train: 0.22945967316627502\n",
      "Train: 0.2479453682899475\n",
      "Train: 0.21393586695194244\n",
      "Train: 0.24539045989513397\n",
      "Train: 0.1829402595758438\n",
      "Train: 0.1822068691253662\n",
      "Train: 0.14872388541698456\n",
      "Train: 0.1808602660894394\n",
      "Train: 0.23114484548568726\n",
      "Train: 0.5014886260032654\n",
      "Test: 0.24299192428588867\n",
      "Test: 0.1846412867307663\n",
      "Test: 0.1858212798833847\n",
      "Train: 0.14361914992332458\n",
      "Train: 0.29196012020111084\n",
      "Train: 0.20471912622451782\n",
      "Train: 0.24882671236991882\n",
      "Train: 0.17937394976615906\n",
      "Train: 0.18348030745983124\n",
      "Train: 0.16393983364105225\n",
      "Train: 0.17998677492141724\n",
      "Train: 0.13663750886917114\n",
      "Train: 0.1517094522714615\n",
      "Train: 0.1817007064819336\n",
      "Train: 0.4752011299133301\n",
      "Test: 0.24619778990745544\n",
      "Test: 0.1874963641166687\n",
      "Test: 0.2046743929386139\n",
      "Train: 0.1438790112733841\n",
      "Train: 0.30039575695991516\n",
      "Train: 0.22135299444198608\n",
      "Train: 0.2481708526611328\n",
      "Train: 0.18037472665309906\n",
      "Train: 0.1707966923713684\n",
      "Train: 0.1568821370601654\n",
      "Train: 0.1514841914176941\n",
      "Train: 0.11797773092985153\n",
      "Train: 0.16458424925804138\n",
      "Train: 0.1797226369380951\n",
      "Train: 0.5029727816581726\n",
      "Test: 0.2313559353351593\n",
      "Test: 0.15498463809490204\n",
      "Test: 0.1824367791414261\n",
      "Train: 0.1275445818901062\n",
      "Train: 0.295730322599411\n",
      "Train: 0.16505873203277588\n",
      "Train: 0.21743617951869965\n",
      "Train: 0.16448600590229034\n",
      "Train: 0.16926582157611847\n",
      "Train: 0.16689595580101013\n",
      "Train: 0.13471999764442444\n",
      "Train: 0.1123967319726944\n",
      "Train: 0.1575404852628708\n",
      "Train: 0.15759047865867615\n",
      "Train: 0.48367735743522644\n",
      "Test: 0.21535100042819977\n",
      "Test: 0.15128439664840698\n",
      "Test: 0.17666226625442505\n",
      "Train: 0.1264166235923767\n",
      "Train: 0.3192383050918579\n",
      "Train: 0.14896181225776672\n",
      "Train: 0.20213614404201508\n",
      "Train: 0.1439456343650818\n",
      "Train: 0.14881759881973267\n",
      "Train: 0.1410471647977829\n",
      "Train: 0.1436229646205902\n",
      "Train: 0.1152612566947937\n",
      "Train: 0.1394050568342209\n",
      "Train: 0.15400919318199158\n",
      "Train: 0.4213796854019165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 0.1484951227903366\n",
      "Test: 0.1422760933637619\n",
      "Test: 0.15098246932029724\n",
      "Train: 0.11848039925098419\n",
      "Train: 0.2788463830947876\n",
      "Train: 0.15021084249019623\n",
      "Train: 0.20600685477256775\n",
      "Train: 0.14274145662784576\n",
      "Train: 0.1428181529045105\n",
      "Train: 0.14259089529514313\n",
      "Train: 0.13383030891418457\n",
      "Train: 0.1208890751004219\n",
      "Train: 0.11885460466146469\n",
      "Train: 0.15150189399719238\n",
      "Train: 0.4146115481853485\n",
      "Test: 0.14137734472751617\n",
      "Test: 0.14399641752243042\n",
      "Test: 0.1673661172389984\n",
      "Loaded pretrained model.\n",
      "Train: 9.223766326904297\n",
      "Train: 6.0139641761779785\n",
      "Train: 6.2979044914245605\n",
      "Train: 1.765523076057434\n",
      "Train: 1.5792012214660645\n",
      "Train: 1.1064223051071167\n",
      "Train: 0.8963019251823425\n",
      "Train: 1.094346523284912\n",
      "Train: 0.9170835018157959\n",
      "Train: 0.7550961971282959\n",
      "Train: 0.7665002942085266\n",
      "Train: 1.1747972965240479\n",
      "Test: 561.0249633789062\n",
      "Test: 579.0541381835938\n",
      "Test: 579.1919555664062\n",
      "Train: 0.6431805491447449\n",
      "Train: 0.8530577421188354\n",
      "Train: 0.6405598521232605\n",
      "Train: 0.5271618366241455\n",
      "Train: 0.4459235966205597\n",
      "Train: 0.4188765585422516\n",
      "Train: 0.41761231422424316\n",
      "Train: 0.3744061291217804\n",
      "Train: 0.4243331849575043\n",
      "Train: 0.327118456363678\n",
      "Train: 0.42431196570396423\n",
      "Train: 0.619387686252594\n",
      "Test: 15.113515853881836\n",
      "Test: 14.210810661315918\n",
      "Test: 15.54049301147461\n",
      "Train: 0.3126007616519928\n",
      "Train: 0.5123405456542969\n",
      "Train: 0.4244731068611145\n",
      "Train: 0.3642847537994385\n",
      "Train: 0.3395959734916687\n",
      "Train: 0.40259528160095215\n",
      "Train: 0.4350208044052124\n",
      "Train: 0.2973894476890564\n",
      "Train: 0.32788389921188354\n",
      "Train: 0.28880298137664795\n",
      "Train: 0.3277953565120697\n",
      "Train: 0.6019327640533447\n",
      "Test: 0.7422323226928711\n",
      "Test: 0.7461576461791992\n",
      "Test: 0.7661307454109192\n",
      "Train: 0.24990320205688477\n",
      "Train: 0.4135555922985077\n",
      "Train: 0.30289462208747864\n",
      "Train: 0.3558731973171234\n",
      "Train: 0.3016412556171417\n",
      "Train: 0.26813453435897827\n",
      "Train: 0.2906606197357178\n",
      "Train: 0.24831411242485046\n",
      "Train: 0.2331981211900711\n",
      "Train: 0.21186017990112305\n",
      "Train: 0.24644820392131805\n",
      "Train: 0.5602426528930664\n",
      "Test: 0.7147426605224609\n",
      "Test: 0.6171972155570984\n",
      "Test: 0.48609039187431335\n",
      "Train: 0.1770947426557541\n",
      "Train: 0.3567051887512207\n",
      "Train: 0.20580428838729858\n",
      "Train: 0.29434219002723694\n",
      "Train: 0.21086525917053223\n",
      "Train: 0.20959362387657166\n",
      "Train: 0.2796388864517212\n",
      "Train: 0.20084206759929657\n",
      "Train: 0.1862356811761856\n",
      "Train: 0.17186184227466583\n",
      "Train: 0.2065490484237671\n",
      "Train: 0.5013597011566162\n",
      "Test: 1.189400553703308\n",
      "Test: 1.0123859643936157\n",
      "Test: 0.9680882096290588\n",
      "Train: 0.14871804416179657\n",
      "Train: 0.32686710357666016\n",
      "Train: 0.20729006826877594\n",
      "Train: 0.2527194619178772\n",
      "Train: 0.1826181858778\n",
      "Train: 0.20787188410758972\n",
      "Train: 0.3206883370876312\n",
      "Train: 0.1651640385389328\n",
      "Train: 0.23013342916965485\n",
      "Train: 0.16799460351467133\n",
      "Train: 0.21734826266765594\n",
      "Train: 0.4866445064544678\n",
      "Test: 0.1993546038866043\n",
      "Test: 0.22371378540992737\n",
      "Test: 0.20058506727218628\n",
      "Train: 0.14727731049060822\n",
      "Train: 0.33834487199783325\n",
      "Train: 0.1802207976579666\n",
      "Train: 0.23819240927696228\n",
      "Train: 0.21745049953460693\n",
      "Train: 0.1962365061044693\n",
      "Train: 0.20827895402908325\n",
      "Train: 0.16103602945804596\n",
      "Train: 0.18598099052906036\n",
      "Train: 0.16325685381889343\n",
      "Train: 0.17585739493370056\n",
      "Train: 0.46144652366638184\n",
      "Test: 0.18569374084472656\n",
      "Test: 0.1733030080795288\n",
      "Test: 0.14163923263549805\n",
      "Train: 0.13930734992027283\n",
      "Train: 0.305948942899704\n",
      "Train: 0.19947554171085358\n",
      "Train: 0.2288743406534195\n",
      "Train: 0.1635163575410843\n",
      "Train: 0.18614548444747925\n",
      "Train: 0.1657276600599289\n",
      "Train: 0.1511533111333847\n",
      "Train: 0.17210902273654938\n",
      "Train: 0.1422295868396759\n",
      "Train: 0.17335721850395203\n",
      "Train: 0.47927984595298767\n",
      "Test: 0.21798057854175568\n",
      "Test: 0.2440165877342224\n",
      "Test: 0.22771942615509033\n",
      "Train: 0.1319652646780014\n",
      "Train: 0.3250705599784851\n",
      "Train: 0.1612444818019867\n",
      "Train: 0.2236979901790619\n",
      "Train: 0.16514991223812103\n",
      "Train: 0.16904811561107635\n",
      "Train: 0.14917582273483276\n",
      "Train: 0.1740521490573883\n",
      "Train: 0.16008901596069336\n",
      "Train: 0.14091555774211884\n",
      "Train: 0.15787014365196228\n",
      "Train: 0.45347830653190613\n",
      "Test: 0.16645988821983337\n",
      "Test: 0.16356438398361206\n",
      "Test: 0.15341345965862274\n",
      "Train: 0.12501077353954315\n",
      "Train: 0.3166593611240387\n",
      "Train: 0.14940862357616425\n",
      "Train: 0.1904713362455368\n",
      "Train: 0.1493028998374939\n",
      "Train: 0.14521333575248718\n",
      "Train: 0.16469499468803406\n",
      "Train: 0.1453905701637268\n",
      "Train: 0.1465459167957306\n",
      "Train: 0.12468592822551727\n",
      "Train: 0.15843580663204193\n",
      "Train: 0.43629923462867737\n",
      "Test: 0.16099591553211212\n",
      "Test: 0.1499462127685547\n",
      "Test: 0.11708703637123108\n",
      "Train: 0.12235328555107117\n",
      "Train: 0.29764339327812195\n",
      "Train: 0.18159238994121552\n",
      "Train: 0.20493961870670319\n",
      "Train: 0.1507161259651184\n",
      "Train: 0.13902944326400757\n",
      "Train: 0.13111364841461182\n",
      "Train: 0.1328406184911728\n",
      "Train: 0.16600841283798218\n",
      "Train: 0.1257091760635376\n",
      "Train: 0.1464565545320511\n",
      "Train: 0.46675705909729004\n",
      "Test: 0.14286261796951294\n",
      "Test: 0.15656468272209167\n",
      "Test: 0.148285910487175\n",
      "Loaded pretrained model.\n",
      "Train: 9.327285766601562\n",
      "Train: 6.161336898803711\n",
      "Train: 5.4881391525268555\n",
      "Train: 1.7846111059188843\n",
      "Train: 1.850644826889038\n",
      "Train: 1.2041454315185547\n",
      "Train: 1.213614583015442\n",
      "Train: 1.3100289106369019\n",
      "Train: 1.130531907081604\n",
      "Train: 0.9252527356147766\n",
      "Train: 0.9175516963005066\n",
      "Train: 0.7168968915939331\n",
      "Test: 579.1272583007812\n",
      "Test: 620.9230346679688\n",
      "Test: 625.5482788085938\n",
      "Train: 0.6802432537078857\n",
      "Train: 0.8688664436340332\n",
      "Train: 0.628728449344635\n",
      "Train: 0.6903918981552124\n",
      "Train: 0.5447604060173035\n",
      "Train: 0.528517484664917\n",
      "Train: 0.5323659181594849\n",
      "Train: 0.4386853277683258\n",
      "Train: 0.3734600245952606\n",
      "Train: 0.35842519998550415\n",
      "Train: 0.36162135004997253\n",
      "Train: 0.2632531523704529\n",
      "Test: 16.724365234375\n",
      "Test: 18.76337242126465\n",
      "Test: 15.31027889251709\n",
      "Train: 0.2997388243675232\n",
      "Train: 0.5311788320541382\n",
      "Train: 0.3614964485168457\n",
      "Train: 0.43938764929771423\n",
      "Train: 0.3221972584724426\n",
      "Train: 0.3142277002334595\n",
      "Train: 0.3566604554653168\n",
      "Train: 0.3035946190357208\n",
      "Train: 0.3447287082672119\n",
      "Train: 0.2758820354938507\n",
      "Train: 0.30689331889152527\n",
      "Train: 0.24707190692424774\n",
      "Test: 1.355994701385498\n",
      "Test: 1.4786491394042969\n",
      "Test: 1.5292505025863647\n",
      "Train: 0.2319955676794052\n",
      "Train: 0.4361253082752228\n",
      "Train: 0.3182884156703949\n",
      "Train: 0.3553614616394043\n",
      "Train: 0.2770398259162903\n",
      "Train: 0.27994272112846375\n",
      "Train: 0.40460696816444397\n",
      "Train: 0.25323325395584106\n",
      "Train: 0.3224966824054718\n",
      "Train: 0.21458959579467773\n",
      "Train: 0.2028975486755371\n",
      "Train: 0.17763440310955048\n",
      "Test: 0.5632304549217224\n",
      "Test: 0.6251000165939331\n",
      "Test: 0.5949938893318176\n",
      "Train: 0.20089446008205414\n",
      "Train: 0.4211828410625458\n",
      "Train: 0.2734515070915222\n",
      "Train: 0.3170172870159149\n",
      "Train: 0.21271410584449768\n",
      "Train: 0.226353719830513\n",
      "Train: 0.30037546157836914\n",
      "Train: 0.21141253411769867\n",
      "Train: 0.22248026728630066\n",
      "Train: 0.18157464265823364\n",
      "Train: 0.1990257203578949\n",
      "Train: 0.19507385790348053\n",
      "Test: 0.3046320080757141\n",
      "Test: 0.4138098359107971\n",
      "Test: 0.5499928593635559\n",
      "Train: 0.1635507047176361\n",
      "Train: 0.39198341965675354\n",
      "Train: 0.19575738906860352\n",
      "Train: 0.2666536867618561\n",
      "Train: 0.17442941665649414\n",
      "Train: 0.1864890307188034\n",
      "Train: 0.22793932259082794\n",
      "Train: 0.1683802455663681\n",
      "Train: 0.19212426245212555\n",
      "Train: 0.17446039617061615\n",
      "Train: 0.1627528965473175\n",
      "Train: 0.15687482059001923\n",
      "Test: 0.27390819787979126\n",
      "Test: 0.2524162232875824\n",
      "Test: 0.5878834128379822\n",
      "Train: 0.13527880609035492\n",
      "Train: 0.3513551354408264\n",
      "Train: 0.20926415920257568\n",
      "Train: 0.22102761268615723\n",
      "Train: 0.1565302461385727\n",
      "Train: 0.14509797096252441\n",
      "Train: 0.1639869213104248\n",
      "Train: 0.15445992350578308\n",
      "Train: 0.184503436088562\n",
      "Train: 0.16690000891685486\n",
      "Train: 0.1336270272731781\n",
      "Train: 0.12856091558933258\n",
      "Test: 0.267311155796051\n",
      "Test: 0.29006052017211914\n",
      "Test: 0.5911809206008911\n",
      "Train: 0.12141945213079453\n",
      "Train: 0.33606192469596863\n",
      "Train: 0.14524851739406586\n",
      "Train: 0.21089470386505127\n",
      "Train: 0.1385330706834793\n",
      "Train: 0.14316906034946442\n",
      "Train: 0.12911319732666016\n",
      "Train: 0.13302288949489594\n",
      "Train: 0.155211940407753\n",
      "Train: 0.13074277341365814\n",
      "Train: 0.11950460821390152\n",
      "Train: 0.12194080650806427\n",
      "Test: 0.161752849817276\n",
      "Test: 0.23847033083438873\n",
      "Test: 0.5122765302658081\n",
      "Train: 0.11200955510139465\n",
      "Train: 0.3289487957954407\n",
      "Train: 0.13890095055103302\n",
      "Train: 0.21196061372756958\n",
      "Train: 0.13859246671199799\n",
      "Train: 0.1476929485797882\n",
      "Train: 0.13280977308750153\n",
      "Train: 0.12976981699466705\n",
      "Train: 0.16838817298412323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.13578687608242035\n",
      "Train: 0.11698294430971146\n",
      "Train: 0.10154145210981369\n",
      "Test: 0.11780941486358643\n",
      "Test: 0.16346503794193268\n",
      "Test: 0.3792361915111542\n",
      "Train: 0.10453977435827255\n",
      "Train: 0.3196810185909271\n",
      "Train: 0.1335659623146057\n",
      "Train: 0.18451890349388123\n",
      "Train: 0.13439741730690002\n",
      "Train: 0.1261638104915619\n",
      "Train: 0.11614283174276352\n",
      "Train: 0.12089095264673233\n",
      "Train: 0.15364034473896027\n",
      "Train: 0.1283969283103943\n",
      "Train: 0.11083647608757019\n",
      "Train: 0.09664690494537354\n",
      "Test: 0.13288642466068268\n",
      "Test: 0.19233573973178864\n",
      "Test: 0.4673595726490021\n",
      "Train: 0.11079910397529602\n",
      "Train: 0.3153994083404541\n",
      "Train: 0.1381772756576538\n",
      "Train: 0.1689322590827942\n",
      "Train: 0.1262952983379364\n",
      "Train: 0.11752308160066605\n",
      "Train: 0.10625173151493073\n",
      "Train: 0.11826445162296295\n",
      "Train: 0.14561405777931213\n",
      "Train: 0.10931752622127533\n",
      "Train: 0.10966067016124725\n",
      "Train: 0.09603403508663177\n",
      "Test: 0.11289454996585846\n",
      "Test: 0.1537202000617981\n",
      "Test: 0.40416219830513\n"
     ]
    }
   ],
   "source": [
    "## Train\n",
    "fullDirList = np.array([groupPath+\"/group_00\",groupPath+\"/group_01\",groupPath+\"/group_02\",groupPath+\"/group_03\",groupPath+\"/group_04\"])\n",
    "inds = np.arange(len(fullDirList))\n",
    "# for partition in range(len(fullDirList)):\n",
    "for partition in range(4):\n",
    "    partition = partition+1\n",
    "    trainInd = np.delete(inds,[partition])\n",
    "    testInd  = inds[partition]\n",
    "    trainDirs = fullDirList[trainInd]\n",
    "    testDir   = [fullDirList[testInd]]\n",
    "    \n",
    "    trainDataset = RegressorDataset([x + \"/img\" for x in trainDirs], [x + \"/seg\" for x in trainDirs], originPath,D=D,N=N,xc=xc,yc=yc,centermode=centermode,mu=mu,sigma=sigma)\n",
    "    testDataset  = RegressorDataset([x + \"/img\" for x in testDir],   [x + \"/seg\" for x in testDir],   originPath,D=D,N=N,xc=xc,yc=yc,centermode=centermode,mu=mu,sigma=sigma)\n",
    "    \n",
    "    trainLoader  = DataLoader(trainDataset,batch_size=batch_size)\n",
    "    testLoader   = DataLoader(testDataset,batch_size=batch_size)\n",
    "    \n",
    "    # Define Net\n",
    "    net = UNet(n_channels=n_channels,n_classes=n_classes)\n",
    "    net.apply_state_dict(pretrained_model)\n",
    "    net.to(device=device)\n",
    "    print(\"Loaded pretrained model.\")\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.RMSprop(net.parameters(),lr=learning_rate,weight_decay=weight_decay,momentum=momentum)\n",
    "    critereon = nn.CrossEntropyLoss()\n",
    "    \n",
    "    #Tensorboard\n",
    "    writer = SummaryWriter('runs/crop_model_partition_'+str(partition))\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        epoch_train_loss = 0\n",
    "        for trainIndex,batch in enumerate(trainLoader,0):\n",
    "            imgs    = batch['img']\n",
    "            segs_gt = batch['seg']\n",
    "            \n",
    "            imgs    = imgs.to(   device=device,dtype=torch.float32)\n",
    "            segs_gt = segs_gt.to(device=device,dtype=torch.long)\n",
    "            \n",
    "            segs_pr = net(imgs)\n",
    "            \n",
    "            loss = critereon(segs_pr,segs_gt)\n",
    "            epoch_train_loss += loss.item()/len(trainLoader)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_value_(net.parameters(),0.1)\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(\"Train: \" + str(loss.item()))\n",
    "            \n",
    "        writer.add_scalar('Training Loss',\n",
    "                        epoch_train_loss,\n",
    "                        epoch)\n",
    "        \n",
    "        net.eval()\n",
    "        epoch_test_loss = 0\n",
    "        for testIndex,batch in enumerate(testLoader,0):\n",
    "            imgs    = batch['img']\n",
    "            segs_gt = batch['seg']\n",
    "            \n",
    "            imgs    = imgs.to(   device=device,dtype=torch.float32)\n",
    "            segs_gt = segs_gt.to(device=device,dtype=torch.long)\n",
    "            \n",
    "            segs_pr = net(imgs)\n",
    "            \n",
    "            loss = critereon(segs_pr,segs_gt)\n",
    "            epoch_test_loss += loss.item()/len(testLoader)\n",
    "            \n",
    "            print(\"Test: \" + str(loss.item()))\n",
    "            \n",
    "        writer.add_scalar('Validation Loss',\n",
    "                        epoch_test_loss,\n",
    "                        epoch)\n",
    "        \n",
    "        savefile = \"D:\\\\autopos\\\\nets\\\\unet-crop-save\" + str(partition) + \"_\" + str(epoch) + \".pth\"\n",
    "        torch.save(net.state_dict(),savefile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
