{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import\n",
    "from __future__ import print_function\n",
    "# from utils.dataset import BasicDataset\n",
    "# from utils.patient import Patient\n",
    "from utils.data import RegressorDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from unet.unet_model import RegressorUNet\n",
    "from unet.unet_parts import SegmentationRegressionLoss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "## Define Dataset\n",
    "\n",
    "import os\n",
    "\n",
    "imgs_dir = \"/Data/ContijochLab/projects/autoseg/train/img/\"\n",
    "segs_dir = \"/Data/ContijochLab/projects/autoseg/train/seg/\"\n",
    "boundbox_path = \"/Data/ContijochLab/projects/autoseg/data/boundbox.csv\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Using GPU')\n",
    "else:\n",
    "    print('Using CPU')\n",
    "\n",
    "dataset = RegressorDataset(imgs_dir,segs_dir,boundbox_path,data_device='cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Data Loader\n",
    "batch_size = 5\n",
    "loader = DataLoader(dataset,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "n_channels = 1\n",
    "n_regress = 2\n",
    "n_bottle = 16\n",
    "n_hidden = 1024\n",
    "n_classes = dataset.__nclass__()\n",
    "img_size = 512\n",
    "lr = 0.001\n",
    "wd = 1e-8\n",
    "mm = 0.9\n",
    "ep = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressorUNet(\n",
       "  (inc): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv2d(64, 13, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (reduce): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(512, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=16384, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1024, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Define Net\n",
    "net = RegressorUNet(n_channels=n_channels, n_classes=n_classes+1,n_regress=n_regress,n_hidden=n_hidden,n_bottle=n_bottle,img_size=img_size)\n",
    "net.to(device=dataset.dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up Optimizer\n",
    "\n",
    "optimizer  = optim.RMSprop(net.parameters(),lr = lr, weight_decay = wd, momentum = mm)\n",
    "critereon  = SegmentationRegressionLoss()  \n",
    "lossweight = .0001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(2.3026, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(9732.4756, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(3.2759, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(1.5897, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(8988.6367, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(2.4885, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(1.2425, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(2317.8767, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(1.4743, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.9744, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(82632.6641, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(9.2376, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.8560, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(49062.3242, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(5.7623, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.7827, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(17087.6309, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(2.4914, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.8165, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(3412.4128, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(1.1577, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.7252, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(2459.5596, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.9711, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.7214, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(5398.0776, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(1.2612, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(1.2371, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(10322.2031, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(2.2693, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(1.0605, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(2821.8435, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(1.3427, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.6812, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(1459.4626, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.8271, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.6317, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(11806.8018, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(1.8124, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5647, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(13857.0859, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(1.9504, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5617, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(23801.8438, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(2.9419, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.6776, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(28549.6855, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(3.5326, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5533, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(7339.5469, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(1.2872, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5533, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(3204.7544, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.8738, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(1.0776, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(564.8123, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(1.1340, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.8596, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(3609.6543, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(1.2205, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5123, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4876.8862, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.9999, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5020, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4774.3901, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.9795, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4923, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4289.6333, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.9213, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4695, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(3491.6328, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.8187, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5870, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(5096.9761, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(1.0967, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4860, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(1359.5516, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.6220, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4743, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(2173.0200, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.6916, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.9213, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4873.4521, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(1.4087, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.7439, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(3766.0547, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(1.1205, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4384, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(3225.3887, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.7610, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4371, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(1462.6741, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5833, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4758, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(641.5319, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5400, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4665, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(3760.7134, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.8426, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5856, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(2530.7466, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.8387, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4401, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4741.3101, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.9142, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4239, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4938.4263, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.9178, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.8787, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(154.8512, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.8942, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.7396, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(346.1115, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.7742, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.4637, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(845.8984, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5482, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4078, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(1340.2177, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5418, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4158, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(847.0192, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5005, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4388, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(382.3444, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4770, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5479, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(1041.2465, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.6521, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4383, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(131.1057, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4514, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4259, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(191.1382, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4450, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.7652, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(78.7798, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.7731, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.6506, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(234.4994, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.6741, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4259, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(135.8478, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4394, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3936, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(310.5925, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4247, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3915, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(270.2379, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4185, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4136, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(281.1401, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4417, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5426, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(243.0871, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5669, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4088, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(58.5209, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4146, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3870, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(291.8108, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4162, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.7600, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(518.9708, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.8119, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.6544, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(254.9519, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.6799, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4079, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(172.1424, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4251, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3708, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(168.6677, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3876, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3751, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(531.6287, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4282, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4010, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(851.9961, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4862, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5311, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(186.9727, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5498, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3995, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(178.1201, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4173, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3784, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(122.6515, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3907, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.7237, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(448.2453, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.7685, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.6355, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(454.9100, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.6810, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3953, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(469.5977, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4422, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3600, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(155.0984, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3756, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3623, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(21.5160, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3645, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3895, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(212.9414, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4108, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5196, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(113.6537, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5309, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3837, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(223.4045, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4061, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3579, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(227.3796, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3806, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.6987, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(73.0514, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.7060, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.6231, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(71.2064, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.6302, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3818, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(115.8895, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3934, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3415, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(96.3482, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3511, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3412, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(20.3332, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3433, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.3749, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(101.5890, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3850, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5087, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(130.0391, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5217, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3537, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(34.1350, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3571, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3252, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(80.4532, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3333, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.6881, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(82.5386, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.6964, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.6164, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(54.7397, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.6218, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3749, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(70.4634, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3819, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3193, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(107.4855, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3301, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3086, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(72.7554, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3158, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3512, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(142.8433, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3655, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4967, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(131.1775, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5098, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3348, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(23.8257, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3372, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3052, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(89.1058, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3141, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.6700, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(121.1064, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.6821, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5983, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(76.0450, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.6059, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3561, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(61.0346, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3622, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3137, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(78.3748, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3215, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2929, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(49.5211, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2978, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3339, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(156.3878, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3496, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4790, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(101.6479, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4892, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3300, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(52.3477, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3353, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2917, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(56.1452, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2973, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.6525, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(98.1023, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.6623, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5948, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(57.0826, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.6006, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3458, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(66.2105, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3524, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2994, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(53.8983, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3048, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2888, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(17.6290, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2906, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3334, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(108.4532, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3443, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4802, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(100.2894, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4902, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3201, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(61.3645, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3262, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2873, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(49.5890, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2923, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.6219, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(68.0006, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.6287, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5641, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(43.4470, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5684, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3561, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(53.3191, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3614, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3086, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(49.0204, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3135, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2706, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(13.9763, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2720, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3132, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(75.9987, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3208, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4510, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(100.6250, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4611, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3140, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(63.5807, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3204, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.2825, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(40.4789, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2866, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.6334, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(49.1587, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.6383, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5567, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(37.0001, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5604, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3390, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(45.6252, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3436, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3121, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(46.1636, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3167, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2766, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(14.8015, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2780, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3125, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(53.3272, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3178, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4414, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(97.3852, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4511, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2945, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(56.8812, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3002, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2653, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(36.2253, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2689, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.6110, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(40.4696, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.6151, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5441, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(34.3676, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5475, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3391, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(36.5108, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3428, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2901, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(41.0865, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2942, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2582, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(12.5986, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2595, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3164, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(42.4738, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3207, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4454, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(98.0340, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4552, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2862, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(39.8713, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2902, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2349, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(31.1531, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2381, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.6080, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(36.5476, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.6116, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5529, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(30.8822, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5560, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3134, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(28.1010, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3162, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2710, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(38.1705, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2748, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2480, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(10.2725, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2490, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2942, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(36.6899, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2979, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4306, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(98.8374, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4405, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2607, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(23.9200, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2631, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2193, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(27.7652, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2221, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5898, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(37.3529, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5935, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5434, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(28.5634, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5463, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3163, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(23.6320, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3187, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2642, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(42.4216, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2685, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2302, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(11.7159, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2314, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2859, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(32.6694, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2891, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4150, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(95.6718, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4246, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2655, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(15.8090, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2671, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2220, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(27.8088, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2248, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5803, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(45.0912, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5848, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5128, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(27.0348, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5155, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.3005, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(22.3677, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3027, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2562, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(54.3884, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2616, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2294, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(17.8018, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2312, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2804, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(31.2154, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2835, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3856, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(96.9475, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3953, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2409, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(15.7736, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2425, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1995, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(18.9051, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2014, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5677, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(79.7620, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5757, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5171, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(28.5508, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5200, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2856, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(18.5410, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2874, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2252, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(67.0131, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2319, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2225, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(29.6146, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2254, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2687, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(52.0680, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2739, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3951, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(74.9901, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4026, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2155, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(13.4439, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2168, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1929, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(16.0281, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1945, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5627, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(181.5325, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5808, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5227, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(90.5563, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5317, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2960, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(39.4751, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3000, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2356, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(47.0532, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2403, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1917, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(25.5382, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1943, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2543, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(134.2165, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2677, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3751, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(102.7565, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3854, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2045, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(40.2881, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2085, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1919, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(21.9739, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1941, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5269, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(120.9514, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5390, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4832, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(81.2755, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4913, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2686, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(61.3121, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2747, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2321, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(57.3101, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2379, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1858, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(28.7348, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1887, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2480, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(98.3274, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2579, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3554, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(132.8807, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3687, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1931, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(194.5008, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2126, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1777, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(111.1267, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1888, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5675, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(57.9924, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5733, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5014, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(142.8891, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5157, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2623, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(154.7735, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2778, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2259, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(194.8785, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2454, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1950, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(151.3153, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2101, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.2551, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(41.2909, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2592, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3724, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(146.5898, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3871, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1887, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(456.5268, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2344, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1783, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(249.7240, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2033, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5365, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(107.7434, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5473, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4806, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(31.9942, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4838, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2717, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(105.3220, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2822, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2149, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(249.6141, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2398, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1877, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(255.0054, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2132, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2474, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(418.0136, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2892, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3564, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(266.5213, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3830, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1896, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(64.0399, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1960, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1676, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(137.0938, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1813, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5365, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(115.0132, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5480, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4823, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(229.2655, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5052, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2538, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(59.2503, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2597, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2082, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(109.7878, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2192, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1928, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(94.4494, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2023, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2183, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(48.8091, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2232, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3407, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(224.4901, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3632, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1831, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(161.0479, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1992, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1604, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(214.7442, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1819, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5400, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(497.6509, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5898, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4800, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(181.5548, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4982, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2466, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(76.8844, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2542, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2124, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(163.8277, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2288, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1913, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(521.1652, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2434, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2245, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(520.8461, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2766, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3321, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(259.8968, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3581, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1776, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(186.4712, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1962, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1609, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(53.0915, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1663, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5192, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(182.1895, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5374, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4738, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(177.6695, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4916, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2458, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(270.5025, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2728, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2041, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(81.0093, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2122, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1695, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(16.2225, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1711, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2262, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(32.2386, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2294, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3422, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(34.3933, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3456, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1617, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(15.7070, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1633, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.1595, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(26.0978, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1621, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5348, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(116.2695, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5464, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4745, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(50.7514, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4796, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2503, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(27.9415, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2531, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2072, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(66.8679, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2139, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1483, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(123.1551, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1606, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2180, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(135.6144, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2315, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3396, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(105.6469, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3501, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1676, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(41.8396, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1718, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1524, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(29.0573, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1553, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5148, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(82.6752, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5230, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4569, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(46.2653, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4615, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2425, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(42.2742, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2468, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2123, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(43.8465, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2167, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1581, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(25.1232, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1606, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2321, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(73.1700, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2394, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3370, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(36.8713, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3407, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1565, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(15.2360, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1580, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1563, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(15.2981, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1578, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5598, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(59.2029, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5657, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4718, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(23.6225, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4742, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2323, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(27.7196, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2350, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2212, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(24.9799, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2237, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1957, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(29.6802, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1986, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2549, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(63.0992, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2612, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3576, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(58.0693, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3634, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1924, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(27.7118, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1952, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1513, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(11.7688, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1525, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5222, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(38.9371, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5261, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4493, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(21.7328, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4514, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2416, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(21.5689, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2438, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2057, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(20.6653, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2077, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1750, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(16.7710, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1767, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2128, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(29.5507, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2158, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3280, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(47.1707, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3327, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1711, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(11.4764, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1722, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1528, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(7.3105, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1535, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5195, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(23.2977, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5218, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4627, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(11.0452, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4638, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.2439, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(15.8169, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2455, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1927, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(25.5747, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1952, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1695, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(8.6039, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1704, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2255, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(27.9988, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2283, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3326, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(44.2004, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3370, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1912, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(7.4859, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1920, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1479, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(6.7549, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1486, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5138, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(35.1610, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5173, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5243, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(11.7799, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5254, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2360, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(13.0074, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2373, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1830, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(32.6232, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1862, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1616, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(7.6716, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1624, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2099, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(32.5961, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2131, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3243, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(36.9790, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3280, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1547, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(9.0401, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1556, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1505, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4.8973, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1510, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5007, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(43.3530, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5051, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4414, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(9.4325, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4423, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2370, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(13.4631, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2383, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1978, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(37.4906, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2015, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1524, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(11.9113, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1536, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1997, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(39.5820, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2037, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3170, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(28.9943, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3199, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1472, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(6.4845, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1478, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1368, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4.2730, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1372, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5254, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(46.9827, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5301, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4697, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(11.1401, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4708, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2132, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(17.8646, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2149, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1791, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(26.5222, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1817, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1500, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(7.2870, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1508, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2020, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(38.4207, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2058, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3132, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(26.6614, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3159, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1393, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(9.5684, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1403, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1306, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(7.2414, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1314, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5002, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(37.2367, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5040, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4284, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(10.8385, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4295, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2257, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(22.7505, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2280, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2018, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(18.4389, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2037, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1485, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(19.6220, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1505, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.2067, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(25.5182, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2092, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3061, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(29.4242, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3090, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1329, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(23.1551, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1352, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1329, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(24.9117, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1354, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5112, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(26.1842, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5138, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4464, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(9.0038, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4473, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2047, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(18.7159, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2066, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1808, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(18.3554, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1826, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1628, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(34.8785, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1663, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1974, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(30.1903, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2004, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3119, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(42.5217, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3161, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1354, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(15.2989, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1370, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1224, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(27.7744, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1252, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4988, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(28.6777, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5017, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4374, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(25.1093, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4399, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2204, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(10.7539, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2214, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1735, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(11.9334, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1747, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1415, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(12.0586, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1427, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1820, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(41.7116, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1862, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3052, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(74.6199, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3127, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1301, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(9.1512, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1310, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1233, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(6.7660, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1239, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4998, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(14.1618, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5013, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4361, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(34.1108, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4395, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1962, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(14.9219, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1977, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1720, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(54.6095, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1774, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1585, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(20.3941, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1605, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1857, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(19.2480, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1876, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3009, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(81.3017, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3090, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1673, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(40.6706, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1714, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1261, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(27.7796, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1289, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4950, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(95.5999, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5045, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4230, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(11.5625, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4241, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1961, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(9.1780, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1970, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1714, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(129.5601, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1844, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1894, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(122.6269, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2017, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1879, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(111.3723, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1991, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2890, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(34.2062, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2924, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1535, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(25.7429, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1561, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.1279, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(49.7762, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1329, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5280, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(226.6966, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5507, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4676, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(92.4073, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4768, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2017, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(50.9476, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2068, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1654, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(21.2146, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1675, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1558, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(17.6203, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1575, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1875, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(152.9044, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2028, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3146, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(108.3911, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3254, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1302, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(50.5338, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1352, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1249, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(15.3739, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1265, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4681, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(42.3919, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4724, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4285, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(36.8150, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4322, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2450, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(71.6126, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2522, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2049, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(74.0150, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2123, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1247, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(118.8506, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1366, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1788, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(32.6848, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1821, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3130, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(46.9542, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3177, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1337, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(84.3497, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1421, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1312, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(155.0355, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1467, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4872, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(164.6624, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5037, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4362, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(87.5179, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4450, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1997, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(16.1935, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2013, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1890, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(49.3895, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1940, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1381, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(130.2548, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1511, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1831, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(198.3798, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2030, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2995, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(237.5889, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3233, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1310, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(75.3074, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1386, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1185, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(30.4004, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1216, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4941, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(11.3057, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4953, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4336, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(85.2454, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4421, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2078, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(47.8472, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2126, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1954, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(112.8695, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2066, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1730, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(82.2778, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1812, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2149, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(36.8621, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2186, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3181, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(74.5475, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3255, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1458, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(45.1436, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1503, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1171, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(40.9520, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1212, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5163, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(239.1191, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5402, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4411, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(77.7218, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4488, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.2378, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(56.1305, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2435, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1869, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(89.6491, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1959, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1606, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(227.3422, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1833, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2006, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(241.3618, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2247, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3270, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(108.1199, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3378, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1463, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(46.0430, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1509, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1237, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(32.7271, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1270, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4921, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(198.4716, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5119, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4390, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(143.9142, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4534, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2004, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(154.3983, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2158, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1768, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(37.8716, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1806, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1358, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(27.8087, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1385, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1783, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(54.5464, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1838, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2975, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(61.4926, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3037, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1236, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(31.3414, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1268, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1271, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(32.5787, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1304, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4753, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(31.4506, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4784, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4071, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(31.4373, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4103, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2403, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(18.3032, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2422, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2246, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(19.7432, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2266, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1594, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(20.2131, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1614, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1918, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(16.3014, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1935, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2837, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(62.6030, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2900, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1361, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(13.4950, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1374, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1192, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(16.1003, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1208, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5258, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(11.2755, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5269, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4608, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(16.9082, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4625, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1531, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(11.9392, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1543, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1415, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(20.0221, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1435, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1738, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(14.2748, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1752, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1679, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(13.6194, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1693, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2899, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(39.8675, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2939, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1285, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(8.7831, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1294, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1024, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(7.6187, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1032, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4870, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(23.2561, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4893, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4355, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(8.1617, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4363, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2178, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(10.0448, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2188, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1773, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(36.2114, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1809, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1477, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(12.9666, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1490, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.1797, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(22.1892, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1819, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2873, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(21.2445, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2894, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1307, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(5.5251, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1313, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1236, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(8.9714, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1245, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4824, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(74.8595, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4899, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4163, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(16.1224, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4179, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1930, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(10.9356, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1941, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1684, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(28.0877, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1712, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1238, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(17.1971, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1255, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1747, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(60.9656, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1808, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3130, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(24.7604, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3155, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1239, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(12.4660, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1251, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1176, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4.7978, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1181, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4708, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(56.8282, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4765, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4202, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(20.9979, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4223, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2054, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(30.4395, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2084, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1863, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(13.2537, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1877, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1462, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(8.4274, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1470, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1775, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(25.7397, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1800, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2960, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(38.3024, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2998, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1243, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(16.7228, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1260, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1101, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(18.5009, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1119, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4801, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(10.1966, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4811, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4209, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(3.1681, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4213, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1842, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(18.2054, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1860, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1641, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(20.7969, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1662, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1176, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(43.4346, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1219, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1589, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(24.0821, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1613, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2901, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(36.9367, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2938, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1140, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(9.8527, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1150, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1083, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(34.5073, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1117, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4771, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(48.8335, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4820, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4066, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(48.0452, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4114, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1984, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(7.1454, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1991, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1926, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(8.4603, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1935, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1808, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(21.0392, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1829, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1834, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(61.7848, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1895, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2808, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(88.3585, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2896, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1226, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(36.4327, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1262, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.1074, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(8.1335, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1082, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5029, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(23.1068, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5053, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4299, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(43.4009, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4342, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1980, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(29.5953, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2009, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1701, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(98.0720, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1799, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1198, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(80.6778, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1278, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1765, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(31.3754, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1797, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2904, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(29.9798, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2934, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1293, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(42.0067, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1335, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1266, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(44.3995, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1310, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4748, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(210.9091, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4959, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4497, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(71.1021, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4568, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1945, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(31.3120, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1977, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1533, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(62.5862, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1596, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1541, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(109.0213, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1650, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1749, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(218.7243, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1968, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2953, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(127.6093, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3080, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1330, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(44.7268, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1375, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1085, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(33.3557, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1119, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4534, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(112.0167, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4646, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4717, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(81.1194, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4798, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2024, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(88.7862, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2112, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2087, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(31.7680, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2118, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2123, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(23.2517, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2147, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2528, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(24.2671, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2552, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4956, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(39.4587, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4995, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1845, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(78.7682, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1924, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1287, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(90.9098, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1378, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4502, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(88.9600, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4591, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4252, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(46.5797, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4299, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1973, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(6.4378, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1980, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1713, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(46.8122, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1759, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1594, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(119.9142, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1714, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1920, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(169.2991, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2089, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3144, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(237.5894, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3381, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1447, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(97.5042, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1544, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1090, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(20.4438, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1111, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4793, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(41.8722, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4835, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4349, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(93.7700, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4443, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.2054, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(76.7781, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2131, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1736, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(114.4843, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1851, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1505, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(65.6738, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1571, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1733, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(46.9641, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1780, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3034, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(42.2950, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3076, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1188, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(32.4275, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1220, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1087, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(46.7985, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1134, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4718, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(203.2496, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4921, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4348, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(76.8700, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4425, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2067, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(33.5539, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2101, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1734, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(33.5902, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1768, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1336, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(82.6549, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1419, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1881, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(187.5007, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2069, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3106, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(115.8381, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3222, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1200, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(43.4007, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1243, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1094, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(16.7177, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1111, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4505, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(99.2970, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4604, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3910, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(92.3662, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4002, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2267, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(78.2572, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2345, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1824, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(30.0188, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1854, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2121, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(15.2286, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2136, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1933, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(15.5893, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1949, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3035, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(46.6878, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3081, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1543, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(53.0807, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1596, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1283, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(33.7682, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1316, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4584, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(7.8443, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4592, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4199, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(5.3376, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4205, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2304, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(11.7333, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2316, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1645, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(32.7444, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1678, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1256, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(59.2793, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1315, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1895, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(57.9990, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1953, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3291, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(45.9393, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3337, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1283, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(12.2652, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1295, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1194, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(32.2477, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1226, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4621, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(14.7275, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4636, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4294, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(36.8376, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4330, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2007, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(12.1563, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2019, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1752, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(24.4032, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1776, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1258, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(37.0239, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1295, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.1709, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(29.7583, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1739, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2841, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(47.4207, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2888, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1153, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(25.8252, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1178, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1032, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(21.6282, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1054, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.5301, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(124.3592, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.5426, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4411, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(74.1700, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4486, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1762, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(35.8847, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1798, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1496, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(51.5535, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1548, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1059, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(43.7913, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1103, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1486, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(73.4936, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1559, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2813, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(63.1580, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2876, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1074, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(32.1250, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1106, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1013, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(19.9118, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1033, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4278, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(119.7862, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4398, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4058, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(42.8206, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4101, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1799, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(23.1385, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1822, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1512, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(22.5162, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1534, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1159, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(26.1257, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1185, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1585, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(96.1468, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1682, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2769, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(63.5110, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2833, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1034, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(12.2690, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1046, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0947, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4.7957, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0952, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4529, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(38.1377, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4568, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4134, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(17.9239, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4152, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1698, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(33.8920, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1732, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1539, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(24.2589, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1564, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1090, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(31.4915, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1122, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1631, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(23.9814, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1655, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2851, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(34.4716, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2885, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0996, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(27.0749, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1023, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0951, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(43.3961, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0995, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3951, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(84.9560, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4036, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3841, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(68.6915, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3910, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1799, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(14.7874, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1814, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1567, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(17.1642, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1584, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1191, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(51.7206, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1243, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1506, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(127.0657, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1633, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2771, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(146.8692, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2918, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0996, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(59.3356, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1056, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.0894, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(15.6885, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0909, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4203, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(6.7509, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4210, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4010, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(64.7449, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4075, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1732, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(49.8818, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1782, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1462, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(74.5152, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1537, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1146, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(48.6619, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1194, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1548, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(22.1716, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1570, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3022, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(22.1770, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3044, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1195, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(27.3039, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1223, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1107, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(30.3298, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1137, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4582, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(252.5484, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4834, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3889, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(125.4354, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4015, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1812, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(60.9466, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1873, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1752, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(36.8302, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1788, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1965, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(80.1853, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2045, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1796, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(177.1484, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1973, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2820, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(158.7664, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2978, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1150, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(58.7510, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1209, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0984, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(24.4860, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1009, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4636, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(71.3911, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4708, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4404, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(64.7059, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4468, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2244, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(80.0303, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2324, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1540, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(26.2455, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1567, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1125, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4.7205, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1130, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1493, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(7.5901, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1501, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3109, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(15.4436, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3124, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1052, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(15.4588, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1067, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1104, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(24.6446, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1129, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4313, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(12.3066, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4325, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4016, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(8.8429, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4025, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1762, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(9.3824, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1771, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1429, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(13.0859, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1442, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1160, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(19.2661, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1180, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1562, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(22.2432, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1584, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2763, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(58.3797, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2822, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0993, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(7.0540, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1000, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0935, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(6.2590, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0941, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3914, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(10.4332, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3925, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3825, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(27.4947, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3853, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.1726, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(18.6861, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1744, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1458, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(21.2881, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1479, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0939, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(0.5491, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0939, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1362, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4.8985, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1367, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2893, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(30.4317, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2924, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0973, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(12.3624, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0986, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0886, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(9.4509, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0896, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3827, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(45.1446, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3872, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3889, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4.8147, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3894, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1587, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(2.8325, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1590, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1339, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(34.0890, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1373, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0960, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(23.3109, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0984, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1407, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(52.2940, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1460, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2781, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(32.4429, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2813, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0898, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4.8302, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0903, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0852, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(3.6811, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0855, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4015, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(84.4241, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4100, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3703, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(40.2870, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3744, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1539, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(29.8359, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1569, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1276, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(7.7982, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1284, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0833, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(1.2597, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0834, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1350, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(33.9405, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1384, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2858, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(34.3522, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2893, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0862, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(25.8357, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0887, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0831, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(14.6863, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0845, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3686, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(8.2341, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3695, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3646, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(3.1784, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3649, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1669, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(15.7743, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1684, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1570, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(12.5127, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1582, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1258, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(22.2388, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1280, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1442, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(16.2915, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1459, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2717, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(20.8426, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2738, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0866, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(2.9676, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0869, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0777, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(16.9350, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0794, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4168, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(38.9559, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4207, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4103, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(45.5685, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4149, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1583, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(9.8461, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1593, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1194, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4.1186, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1198, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0783, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(11.8248, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0795, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.1238, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(49.7916, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1287, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2872, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(83.2067, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2955, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0852, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(53.9810, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0906, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0837, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(16.0015, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0853, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3533, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(22.6342, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3556, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3698, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(17.2092, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3715, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1548, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(25.2162, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1573, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1314, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(77.5651, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1392, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0845, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(61.5745, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0907, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1373, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(43.5339, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1417, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2740, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(12.4606, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2752, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0859, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(7.7091, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0867, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0773, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(12.7638, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0786, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3701, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(137.4010, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3838, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3700, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(57.9395, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3758, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1615, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(37.1207, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1652, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1253, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(14.8389, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1268, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0794, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(16.6617, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0811, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1389, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(79.1908, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1468, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3179, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(56.1698, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3235, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0839, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(35.2514, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0874, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0816, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(14.7699, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0830, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3537, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(34.2377, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3571, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3845, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(25.4446, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3871, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1807, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(31.8394, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1839, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1523, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(14.4185, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1537, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1303, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(12.4306, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1316, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1354, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4.5265, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1358, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2922, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(16.1912, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2939, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0919, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(16.2387, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0935, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0765, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(20.6510, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0786, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3526, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(13.2649, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3539, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4099, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(9.7127, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4109, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1601, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(5.7222, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1607, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1333, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(10.1481, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1343, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0858, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(33.0040, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0891, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1347, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(56.9090, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1404, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3054, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(63.3817, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3117, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0942, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(13.5291, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0956, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.0841, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4.2830, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0846, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4190, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(17.3960, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4207, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3296, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(49.5421, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3345, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1806, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(26.9418, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1833, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1354, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(28.1467, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1382, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0835, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(6.2324, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0841, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1253, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(30.2158, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1283, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2753, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(60.1141, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2813, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0796, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(39.4020, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0835, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0743, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(17.8245, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0760, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4308, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(135.0938, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4443, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4078, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(62.2722, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4140, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1579, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(30.9637, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1610, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1632, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(59.2755, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1691, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1580, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(69.2118, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1649, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1600, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(109.1586, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1709, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2707, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(73.3466, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2781, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0955, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(19.0570, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0974, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0826, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(1.9087, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0827, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4384, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(90.5930, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4474, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4259, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(72.2700, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4332, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1742, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(69.6940, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1811, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1264, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(23.9298, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1288, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1058, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(3.0655, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1061, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1391, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(14.6299, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1405, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3241, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(24.6485, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3266, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0986, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(24.7359, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1011, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0896, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(26.2060, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0922, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3869, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(8.6377, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3877, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3640, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(6.7633, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3647, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1939, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(15.8252, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1955, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1322, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(17.0952, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1340, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1126, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(30.9122, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1157, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1526, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(49.5333, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1575, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2928, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(59.6623, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2988, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0919, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(13.9671, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0933, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0841, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(6.7917, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0848, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3771, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(23.9275, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3795, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4259, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(65.3467, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4324, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.1622, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(37.3182, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1659, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1293, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(23.7252, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1317, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0876, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(1.0733, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0877, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1239, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(15.9380, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1255, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2786, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(45.8370, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2832, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0910, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(53.9900, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0964, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0858, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(26.3468, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0885, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3648, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(141.4799, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3790, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3592, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(37.5760, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3630, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1489, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(7.9326, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1497, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1147, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(61.4860, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1209, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0714, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(77.7671, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0791, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1219, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(169.7988, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1389, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3280, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(123.6266, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3404, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0899, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(53.6686, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0953, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0709, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(15.1854, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0724, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3256, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(126.5486, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3382, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3474, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(111.3972, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3586, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1613, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(114.7085, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1728, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1656, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(25.1797, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1681, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1490, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(1.3770, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1491, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1770, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(16.0008, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1786, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2764, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(39.9290, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2803, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0876, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(26.7915, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0903, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0755, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(21.9182, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0777, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3888, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(7.1273, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3896, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.4236, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(2.8466, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.4239, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1550, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(8.7473, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1559, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1362, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(8.8971, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1371, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0982, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(10.0124, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0992, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1447, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(16.3817, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1464, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.2957, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(24.4308, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.2982, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1753, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(3.5885, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1757, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0786, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4.4856, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0791, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3267, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(15.6044, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3282, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3561, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(27.2496, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3588, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1707, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(20.8170, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1728, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1173, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(14.3152, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1187, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0915, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(0.6435, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0916, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE:  tensor(0.1883, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(15.3220, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1898, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3043, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(35.0780, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3078, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0847, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(38.9772, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0886, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0817, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(19.1049, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0836, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3609, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(34.4753, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3644, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3527, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(2.6030, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3529, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1572, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(14.2934, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1586, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1249, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(52.6525, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1301, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0753, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(31.0634, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0784, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1372, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(58.5125, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1430, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3527, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(25.0095, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3552, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.1120, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4.8366, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.1125, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.0801, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(4.0050, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.0805, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3174, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(105.2718, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3279, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "CE:  tensor(0.3694, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "MSE: tensor(72.7999, device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "L:   tensor(0.3767, device='cuda:1', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "## Train\n",
    "\n",
    "for epoch in range(ep):\n",
    "    net.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in loader:\n",
    "        imgs = batch['img']\n",
    "        segs_gt = batch['seg']\n",
    "        regs_gt = batch['org']\n",
    "\n",
    "        imgs = imgs.to(device=dataset.dev, dtype=torch.float32)\n",
    "        segs_gt = segs_gt.to(device=dataset.dev, dtype = torch.long)\n",
    "        regs_gt = regs_gt.to(device=dataset.dev, dtype = torch.float32)\n",
    "\n",
    "        segs_pr,regs_pr = net(imgs)\n",
    "\n",
    "        loss = critereon(segs_pr,regs_pr,segs_gt,regs_gt,lossweight)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_value_(net.parameters(),0.1)\n",
    "        optimizer.step()\n",
    "\n",
    "#         print(loss.to(device='cpu').detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
