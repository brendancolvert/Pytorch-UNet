{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import\n",
    "from __future__ import print_function\n",
    "from utils.dataset import BasicDataset\n",
    "from utils.patient import Patient\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from unet.unet_model import UNet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bool_to_float(v):\n",
    "    if v == True:\n",
    "        return 1\n",
    "    elif v == False:\n",
    "        return 0\n",
    "    else:\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicDataset with 45 items. Image dim: 512x512. Num channels: 1. Device: cuda. \n"
     ]
    }
   ],
   "source": [
    "## Define Dataset\n",
    "\n",
    "imgpath = \"/Data/ContijochLab/projects/autoseg/train/img/\"\n",
    "segpath = \"/Data/ContijochLab/projects/autoseg/train/seg/\"\n",
    "\n",
    "dataset = BasicDataset(imgpath,segpath,data_device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Data Loader\n",
    "batch_size = 5\n",
    "loader = DataLoader(dataset,batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "n_channels = 1\n",
    "n_classes = dataset.__nclass__()\n",
    "lr = 0.001\n",
    "wd = 1e-8\n",
    "mm = 0.9\n",
    "ep = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (inc): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv2d(64, 13, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Define Net\n",
    "net = UNet(n_channels=n_channels, n_classes=n_classes+1)\n",
    "net.to(device=dataset.dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up Optimizer\n",
    "\n",
    "optimizer = optim.RMSprop(net.parameters(),lr = lr, weight_decay = wd, momentum = mm)\n",
    "critereon = nn.CrossEntropyLoss()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train or Load\n",
    "\n",
    "loadnet = True\n",
    "\n",
    "if not loadnet:\n",
    "\n",
    "    for epoch in range(ep):\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        for batch in loader:\n",
    "            imgs = batch['img']\n",
    "            segs_gt = batch['seg']\n",
    "\n",
    "            imgs = imgs.to(device=dataset.dev, dtype=torch.float32)\n",
    "            segs_gt = segs_gt.to(device=dataset.dev, dtype = torch.long)\n",
    "\n",
    "            segs_pr = net(imgs)\n",
    "\n",
    "            loss = critereon(segs_pr,segs_gt)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_value_(net.parameters(),0.1)\n",
    "            optimizer.step()\n",
    "\n",
    "            print(str(loss))\n",
    "else:\n",
    "    loadfile = \"/Experiment/unet-save.pth\"\n",
    "    net.load_state_dict(torch.load(loadfile, map_location=dataset.dev))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Net\n",
    "savefile = \"/Experiment/unet-save.pth\"\n",
    "torch.save(net.state_dict(),savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Probability maps\n",
    "net.eval()\n",
    "\n",
    "testloader = DataLoader(dataset,batch_size=1)\n",
    "\n",
    "for testbatch in testloader:\n",
    "    testimgs, testsegs_gt = testbatch['img'],testbatch['seg']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        testsegs_pr = net(testimgs)\n",
    "    testsegs_pr = torch.softmax(testsegs_pr,dim=1)\n",
    "    _,testsegs_cl = torch.max(testsegs_pr,dim=1)\n",
    "    testsegs_pr = testsegs_pr.to(device='cpu')\n",
    "    testsegs_cl = testsegs_cl.to(device='cpu')\n",
    "    fig1,ax1 = plt.subplots(3,4)\n",
    "    fig1.set_figwidth(20)\n",
    "    fig1.set_figheight(14)\n",
    "    for axInd in range(n_classes):        \n",
    "        if axInd < 4:\n",
    "            ax1[0,axInd%4].imshow(testsegs_pr[0,axInd+1,:,:].numpy(),vmin = 0, vmax = 1)\n",
    "        elif axInd < 8:\n",
    "            ax1[1,axInd%4].imshow(testsegs_pr[0,axInd+1,:,:].numpy(),vmin = 0, vmax = 1)\n",
    "        else:\n",
    "            ax1[2,axInd%4].imshow(testsegs_pr[0,axInd+1,:,:].numpy(),vmin = 0, vmax = 1)\n",
    "            \n",
    "    fig2,ax2 = plt.subplots(3,4)\n",
    "    fig2.set_figwidth(20)\n",
    "    fig2.set_figheight(14)\n",
    "    for axInd in range(n_classes):\n",
    "#         X = (testsegs_cl[0,:,:].numpy()>(axInd+1-0.1) & testsegs_cl[0,:,:].numpy()<(axInd+1+0.1))\n",
    "        X = testsegs_cl[0,:,:].numpy() == (axInd+1)\n",
    "        X = X.astype(np.float)\n",
    "        if axInd < 4:\n",
    "            ax2[0,axInd%4].imshow(X,vmin = 0, vmax = 1)\n",
    "        elif axInd < 8:\n",
    "            ax2[1,axInd%4].imshow(X,vmin = 0, vmax = 1)\n",
    "        else:\n",
    "            ax2[2,axInd%4].imshow(X,vmin = 0, vmax = 1)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Test Net on Training Data\n",
    "\n",
    "net.eval()\n",
    "\n",
    "tot = 0\n",
    "\n",
    "testloader = DataLoader(dataset,batch_size=1)\n",
    "\n",
    "for testbatch in testloader:\n",
    "    testimgs, testsegs_gt = testbatch['img'],testbatch['seg']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        testsegs_pr = net(testimgs)\n",
    "    \n",
    "    _,testsegs_cl = torch.max(testsegs_pr,dim=1)\n",
    "    \n",
    "    testimgs = testimgs.to(device='cpu')\n",
    "    testsegs_gt = testsegs_gt.to(device='cpu')\n",
    "    testsegs_cl = testsegs_cl.to(device='cpu')\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3)\n",
    "    fig.set_figwidth(15)\n",
    "    ax[0].imshow(testimgs[0,0,:,:].numpy(),vmin = -1000, vmax=1000)\n",
    "    ax[1].imshow(testsegs_gt[0,:,:].numpy(),vmin = 0, vmax = 12)\n",
    "    ax[2].imshow(testsegs_cl[0,:,:].numpy(),vmin = 0, vmax = 12)\n",
    "    plt.show(fig)\n",
    "    \n",
    "    plt.show(fig)\n",
    "    time.sleep(0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[5 6 7 8 9]\n",
      "[10 11 12 13 14]\n",
      "[15 16 17 18 19]\n",
      "[20 21 22 23 24]\n",
      "[25 26 27 28 29]\n",
      "[30 31 32 33 34]\n",
      "[35 36 37 38 39]\n",
      "[40 41 42 43 44]\n",
      "[45 46 47 48 49]\n",
      "[50 51 52 53 54]\n",
      "[55 56 57 58 59]\n",
      "[60 61 62 63]\n"
     ]
    }
   ],
   "source": [
    "## Load Patient and Predict\n",
    "\n",
    "# pat_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1901281601/img-nii/CTCAC1901281601.nii.gz\"\n",
    "# seg_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1901281601/s04-nii/CTCAC1901281601.nii.gz\"\n",
    "\n",
    "# pat_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1901281608/img-nii/CTCAC1901281608.nii.gz\"\n",
    "# seg_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1901281608/s04-nii/CTCAC1901281608.nii.gz\"\n",
    "\n",
    "# pat_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1903181826/img-nii/CTCAC1903181826.nii.gz\"\n",
    "# seg_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1903181826/s04-nii/CTCAC1903181826.nii.gz\"\n",
    "\n",
    "# pat_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1906061647/img-nii/CTCAC1906061647.nii.gz\"\n",
    "# seg_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1906061647/s04-nii/CTCAC1906061647.nii.gz\"\n",
    "\n",
    "# pat_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1906071329/img-nii/CTCAC1906071329.nii.gz\"\n",
    "# seg_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1906071329/s04-nii/CTCAC1906071329.nii.gz\"\n",
    "\n",
    "pat_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1906071741/img-nii/CTCAC1906071741.nii.gz\"\n",
    "seg_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1906071741/s04-nii/CTCAC1906071741.nii.gz\"\n",
    "\n",
    "patient = Patient(pat_file,data_device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "patient.predict(net,seg_file,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
