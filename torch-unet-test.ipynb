{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Status: True\n"
     ]
    }
   ],
   "source": [
    "## Import\n",
    "from __future__ import print_function\n",
    "from utils.dataset import BasicDataset\n",
    "from utils.patient import Patient\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from unet.unet_model import UNet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import glob\n",
    "\n",
    "print(\"CUDA Status: \" + str(torch.cuda.is_available()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Dataset\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "imgpath = \"C:/Users/brend/Data/autoseg/train/img/\"\n",
    "segpath = \"C:/Users/brend/Data/autoseg/train/seg/\"\n",
    "\n",
    "fls = os.listdir(imgpath)\n",
    "\n",
    "dataset = BasicDataset(imgpath,segpath,data_device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Data Loader\n",
    "batch_size = 10\n",
    "loader = DataLoader(dataset,batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "n_channels = 1\n",
    "n_classes = dataset.__nclass__()\n",
    "lr = 0.001\n",
    "wd = 1e-8\n",
    "mm = 0.9\n",
    "ep = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (inc): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv2d(64, 13, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Define Net\n",
    "net = UNet(n_channels=n_channels, n_classes=n_classes+1)\n",
    "net.to(device=dataset.dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up Optimizer\n",
    "\n",
    "optimizer = optim.RMSprop(net.parameters(),lr = lr, weight_decay = wd, momentum = mm)\n",
    "critereon = nn.CrossEntropyLoss()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5761, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(2.3988, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(1.5775, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(1.1296, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.7995, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.8044, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.6975, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.6093, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.6037, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.5876, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.5220, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.5064, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.5193, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.5669, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.5595, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.4313, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.4480, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.4731, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.4482, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.4586, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.4360, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.5189, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.4093, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.4147, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.4273, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.3816, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.3697, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.3791, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.3688, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.3982, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.3360, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.3519, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.3416, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.3505, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.3483, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.3140, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.3257, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.3173, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.3131, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.3081, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.3040, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.3015, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2890, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.3346, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2804, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2686, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.3132, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2776, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2936, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2848, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2589, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2848, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2438, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2554, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2447, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2340, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2493, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2399, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2399, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2525, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2293, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2456, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2425, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2734, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2167, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2339, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2540, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2172, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2404, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2449, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2021, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2210, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2001, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2085, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1908, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2089, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2170, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1949, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2138, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2124, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1817, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2044, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1850, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1995, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1721, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1864, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2133, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1751, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1847, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1697, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1717, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1999, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1756, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1902, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1677, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1590, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1947, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1591, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1697, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1439, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1622, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1899, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1521, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1770, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1561, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1373, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1831, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1438, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1615, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1386, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1383, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1751, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1459, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1543, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1487, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1247, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1558, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1432, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1406, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1410, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1250, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1660, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1460, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1378, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1424, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1301, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1486, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1404, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1521, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1261, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1293, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1665, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1274, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1507, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1143, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1138, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1598, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1233, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1394, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1148, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1747, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1937, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1293, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2142, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1316, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1360, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.2451, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1495, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1591, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1562, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1590, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1831, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1754, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1901, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1610, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1551, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1774, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1720, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1763, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1520, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1362, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1611, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1391, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1597, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1282, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1196, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1540, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1172, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1205, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1183, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1119, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1306, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1186, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1177, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1126, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1070, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1341, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1068, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1177, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1041, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1011, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1268, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1050, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1160, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0968, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0989, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1232, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1017, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1114, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0921, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0935, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1178, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1062, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1046, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0892, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0937, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1141, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0941, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1018, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0964, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0892, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0995, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1094, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0921, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0930, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1078, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1361, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1035, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1096, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0894, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1002, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1120, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0994, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1069, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0950, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1038, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1164, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1255, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0974, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0945, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0976, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1389, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1011, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1233, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0867, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0951, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1121, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0960, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0961, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0908, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0843, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1117, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0852, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1001, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0888, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0794, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0948, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0813, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0995, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0808, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0842, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1006, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0819, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.1045, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0749, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0755, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0982, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0889, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0874, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0711, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0855, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0916, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0838, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0928, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0820, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0757, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0943, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0814, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0889, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0724, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0774, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0965, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0739, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0874, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0682, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0790, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0893, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0756, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0868, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0730, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0708, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0893, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0687, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0879, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0669, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0656, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0807, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0744, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0814, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0641, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0691, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0843, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0664, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0780, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0659, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0630, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0792, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0657, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0838, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0620, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0655, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0801, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0685, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0763, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0613, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0632, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0802, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0637, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0787, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0592, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0594, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0799, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0653, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0749, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0661, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0621, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0786, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0604, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0853, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0586, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0612, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0845, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0669, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0767, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0563, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0704, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0793, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0747, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0828, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0586, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0730, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0877, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0675, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0928, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0760, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0625, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0879, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0665, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0786, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0699, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0614, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0786, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0615, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0713, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0608, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0608, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0690, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0629, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0729, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0589, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0586, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0708, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0589, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0676, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0553, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0578, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0654, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0613, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0717, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0553, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0590, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0765, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0556, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0706, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0627, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0542, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0706, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0590, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0669, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0586, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0594, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0665, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0578, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0715, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0554, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0586, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0665, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0628, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0700, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0532, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0583, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0691, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0629, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0748, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0538, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0612, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0747, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0595, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0663, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0602, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0581, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0679, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0548, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0699, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0524, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0537, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0715, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0599, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0622, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0540, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0635, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0701, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0568, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0724, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0547, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0570, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0734, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0619, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0746, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0598, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0553, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0653, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0551, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0626, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0556, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0518, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0664, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0563, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0632, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0521, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0546, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0643, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0517, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0652, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0489, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0557, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0595, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0528, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0649, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0485, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0563, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0634, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0560, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0632, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0466, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0554, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0683, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0579, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0702, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0587, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0583, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0666, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0541, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0567, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0577, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0491, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0591, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0511, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0606, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0503, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0551, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0595, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0497, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0551, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0472, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0485, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0568, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0504, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0582, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0455, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0500, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0592, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0473, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0601, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0479, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0473, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0570, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0487, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0589, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0458, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0516, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0549, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0555, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0547, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0416, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0511, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0626, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0503, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0607, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0441, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0512, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0596, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0516, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0535, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0428, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0476, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0543, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0508, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0592, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0428, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0528, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0638, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0463, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0576, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0503, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0471, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0565, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0496, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0530, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0469, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0503, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0581, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0558, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0594, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0423, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0550, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0666, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0533, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0613, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n",
      "tensor(0.0451, device='cuda:0', grad_fn=<NllLoss2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "## Train or Load\n",
    "\n",
    "loadnet = False\n",
    "\n",
    "if not loadnet:\n",
    "\n",
    "    for epoch in range(ep):\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        for batch in loader:\n",
    "            imgs = batch['img']\n",
    "            segs_gt = batch['seg']\n",
    "\n",
    "            imgs = imgs.to(device=dataset.dev, dtype=torch.float32)\n",
    "            segs_gt = segs_gt.to(device=dataset.dev, dtype = torch.long)\n",
    "\n",
    "            segs_pr = net(imgs)\n",
    "\n",
    "            loss = critereon(segs_pr,segs_gt)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_value_(net.parameters(),0.1)\n",
    "            optimizer.step()\n",
    "\n",
    "            print(str(loss))\n",
    "else:\n",
    "    loadfile = \"C:/Users/brend/Data/autoseg/unet-save.pth\"\n",
    "    net.load_state_dict(torch.load(loadfile, map_location=dataset.dev))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Net\n",
    "savefile = \"C:/Users/brend/Data/autoseg/unet-save.pth\"\n",
    "torch.save(net.state_dict(),savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Probability maps\n",
    "net.eval()\n",
    "\n",
    "testloader = DataLoader(dataset,batch_size=1)\n",
    "\n",
    "for testbatch in testloader:\n",
    "    testimgs, testsegs_gt = testbatch['img'],testbatch['seg']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        testsegs_pr = net(testimgs)\n",
    "    testsegs_pr = torch.softmax(testsegs_pr,dim=1)\n",
    "    _,testsegs_cl = torch.max(testsegs_pr,dim=1)\n",
    "    testsegs_pr = testsegs_pr.to(device='cpu')\n",
    "    testsegs_cl = testsegs_cl.to(device='cpu')\n",
    "    fig1,ax1 = plt.subplots(3,4)\n",
    "    fig1.set_figwidth(20)\n",
    "    fig1.set_figheight(14)\n",
    "    for axInd in range(n_classes):        \n",
    "        if axInd < 4:\n",
    "            ax1[0,axInd%4].imshow(testsegs_pr[0,axInd+1,:,:].numpy(),vmin = 0, vmax = 1)\n",
    "        elif axInd < 8:\n",
    "            ax1[1,axInd%4].imshow(testsegs_pr[0,axInd+1,:,:].numpy(),vmin = 0, vmax = 1)\n",
    "        else:\n",
    "            ax1[2,axInd%4].imshow(testsegs_pr[0,axInd+1,:,:].numpy(),vmin = 0, vmax = 1)\n",
    "            \n",
    "    fig2,ax2 = plt.subplots(3,4)\n",
    "    fig2.set_figwidth(20)\n",
    "    fig2.set_figheight(14)\n",
    "    for axInd in range(n_classes):\n",
    "#         X = (testsegs_cl[0,:,:].numpy()>(axInd+1-0.1) & testsegs_cl[0,:,:].numpy()<(axInd+1+0.1))\n",
    "        X = testsegs_cl[0,:,:].numpy() == (axInd+1)\n",
    "        X = X.astype(np.float)\n",
    "        if axInd < 4:\n",
    "            ax2[0,axInd%4].imshow(X,vmin = 0, vmax = 1)\n",
    "        elif axInd < 8:\n",
    "            ax2[1,axInd%4].imshow(X,vmin = 0, vmax = 1)\n",
    "        else:\n",
    "            ax2[2,axInd%4].imshow(X,vmin = 0, vmax = 1)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Test Net on Training Data\n",
    "\n",
    "net.eval()\n",
    "\n",
    "tot = 0\n",
    "\n",
    "testloader = DataLoader(dataset,batch_size=1)\n",
    "\n",
    "for testbatch in testloader:\n",
    "    testimgs, testsegs_gt = testbatch['img'],testbatch['seg']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        testsegs_pr = net(testimgs)\n",
    "    \n",
    "    _,testsegs_cl = torch.max(testsegs_pr,dim=1)\n",
    "    \n",
    "    testimgs = testimgs.to(device='cpu')\n",
    "    testsegs_gt = testsegs_gt.to(device='cpu')\n",
    "    testsegs_cl = testsegs_cl.to(device='cpu')\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3)\n",
    "    fig.set_figwidth(15)\n",
    "    ax[0].imshow(testimgs[0,0,:,:].numpy(),vmin = -1000, vmax=1000)\n",
    "    ax[1].imshow(testsegs_gt[0,:,:].numpy(),vmin = 0, vmax = 12)\n",
    "    ax[2].imshow(testsegs_cl[0,:,:].numpy(),vmin = 0, vmax = 12)\n",
    "    plt.show(fig)\n",
    "    \n",
    "    plt.show(fig)\n",
    "    time.sleep(0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/brend/Data/autoseg/predict\\CTCAC1901281601\n",
      "[0 1 2 3 4]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-00c95e42e4de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mpatient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPatient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cuda'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mpatient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msegfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Git\\Pytorch-UNet\\utils\\patient.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, net, seg_file, batch_size)\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[0msegdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Predict\n",
    "\n",
    "predict_path = \"C:/Users/brend/Data/autoseg/predict\"\n",
    "\n",
    "for filename in glob.glob(predict_path+\"/CTCAC*\"):\n",
    "    print(filename)\n",
    "    fnspl = filename.split(\"\\\\\")\n",
    "    if not os.path.exists(filename + \"/s04-nii\"):\n",
    "        os.mkdir(filename + \"/s04-nii\")\n",
    "    patfile = filename + \"/img-nii/\" + fnspl[-1] + \".nii.gz\"\n",
    "    segfile = filename + \"/s04-nii/\" + fnspl[-1] + \".nii.gz\"\n",
    "    \n",
    "    patient = Patient(patfile,data_device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    patient.predict(net,segfile,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Patient and Predict\n",
    "\n",
    "# pat_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1901281601/img-nii/CTCAC1901281601.nii.gz\"\n",
    "# seg_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1901281601/s04-nii/CTCAC1901281601.nii.gz\"\n",
    "\n",
    "# pat_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1901281608/img-nii/CTCAC1901281608.nii.gz\"\n",
    "# seg_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1901281608/s04-nii/CTCAC1901281608.nii.gz\"\n",
    "\n",
    "# pat_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1903181826/img-nii/CTCAC1903181826.nii.gz\"\n",
    "# seg_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1903181826/s04-nii/CTCAC1903181826.nii.gz\"\n",
    "\n",
    "# pat_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1906061647/img-nii/CTCAC1906061647.nii.gz\"\n",
    "# seg_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1906061647/s04-nii/CTCAC1906061647.nii.gz\"\n",
    "\n",
    "# pat_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1906071329/img-nii/CTCAC1906071329.nii.gz\"\n",
    "# seg_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1906071329/s04-nii/CTCAC1906071329.nii.gz\"\n",
    "\n",
    "pat_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1906071741/img-nii/CTCAC1906071741.nii.gz\"\n",
    "seg_file = \"/Data/ContijochLab/projects/autoseg/predict/CTCAC1906071741/s04-nii/CTCAC1906071741.nii.gz\"\n",
    "\n",
    "patient = Patient(pat_file,data_device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "patient.predict(net,seg_file,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
